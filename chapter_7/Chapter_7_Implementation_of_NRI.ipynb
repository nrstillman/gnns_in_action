{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LBBdBc9ZILPQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.dataset import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7T1S4BkgNiL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lg1uRj7qgQAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7e5e7c-494c-4097-fc1e-4ccb502d195f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "6i1Vk8x9HN_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a19655-3a73-4bb1-e8cc-ed820035799d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=5332f02a6be311586af6fde62cd5317e2bd716071c697ce0f565e3321a91b1ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# Code from NRI.\n",
        "def normalize(data, data_max, data_min):\n",
        "\treturn (data - data_min) * 2 / (data_max - data_min) - 1\n",
        "\n",
        "\n",
        "def unnormalize(data, data_max, data_min):\n",
        "\treturn (data + 1) * (data_max - data_min) / 2. + data_min\n",
        "\n",
        "\n",
        "def get_edge_inds(num_vars):\n",
        "\tedges = []\n",
        "\tfor i in range(num_vars):\n",
        "\t\tfor j in range(num_vars):\n",
        "\t\t\tif i == j:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tedges.append([i, j])\n",
        "\treturn edges\n",
        "\n",
        "class CmuMotionData(Dataset):\n",
        "    def __init__(self, name, data_path, mode, data_len=-1, expand_train=False, test_full=False, mask_ind_file=None):\n",
        "        self.name = name\n",
        "        self.data_path = data_path\n",
        "        self.mode = mode\n",
        "        self.train_data_len = data_len\n",
        "        # Get preprocessing stats.\n",
        "        loc_max, loc_min, vel_max, vel_min = self._get_normalize_stats()\n",
        "        self.loc_max = loc_max\n",
        "        self.loc_min = loc_min\n",
        "        self.vel_max = vel_max\n",
        "        self.vel_min = vel_min\n",
        "        self.test_full = test_full\n",
        "\n",
        "        # Load data.\n",
        "        self._load_data()\n",
        "        self.expand_train = expand_train\n",
        "        if self.mode == 'train' and self.expand_train and self.train_data_len > 0:\n",
        "            self.all_inds = []\n",
        "            for ind in range(len(self.feat)):\n",
        "                t_ind = 0\n",
        "                while t_ind < len(self.feat[ind]):\n",
        "                    self.all_inds.append((ind, t_ind))\n",
        "                    t_ind += self.train_data_len\n",
        "        else:\n",
        "            self.expand_train = False\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.expand_train:\n",
        "            ind, t_ind = self.all_inds[index]\n",
        "            start_ind = np.random.randint(t_ind, t_ind + self.train_data_len)\n",
        "\n",
        "            feat = self.feat[ind][start_ind:start_ind + self.train_data_len]\n",
        "            if len(feat) < self.train_data_len:\n",
        "                feat = self.feat[ind][-self.train_data_len:]\n",
        "            return {'inputs':feat}\n",
        "        else:\n",
        "            inputs = self.feat[index]\n",
        "            size = len(inputs)\n",
        "            if self.mode == 'train' and self.train_data_len > 0 and size > self.train_data_len:\n",
        "                start_ind = np.random.randint(0, size-self.train_data_len)\n",
        "                inputs = inputs[start_ind:start_ind+self.train_data_len]\n",
        "            result = {'inputs': inputs}\n",
        "        return result\n",
        "\n",
        "    def __len__(self, ):\n",
        "        if self.expand_train:\n",
        "            return len(self.all_inds)\n",
        "        else:\n",
        "            return len(self.feat)\n",
        "\n",
        "    def _get_normalize_stats(self,):\n",
        "        train_loc = np.load(self._get_npy_path('loc', 'train'), allow_pickle=True)\n",
        "        train_vel = np.load(self._get_npy_path('vel', 'train'), allow_pickle=True)\n",
        "        try:\n",
        "            train_loc.max()\n",
        "            self.dynamic_len = False\n",
        "        except:\n",
        "            self.dynamic_len = True\n",
        "        if self.dynamic_len:\n",
        "            max_loc = max(x.max() for x in train_loc)\n",
        "            min_loc = min(x.min() for x in train_loc)\n",
        "            max_vel = max(x.max() for x in train_vel)\n",
        "            min_vel = min(x.min() for x in train_vel)\n",
        "            return max_loc, min_loc, max_vel, min_vel\n",
        "        else:\n",
        "            return train_loc.max(), train_loc.min(), train_vel.max(), train_vel.min()\n",
        "\n",
        "    def _load_data(self, ):\n",
        "        #print('***Experiment hack: evaling on training.***')\n",
        "        # Load data\n",
        "        self.loc_feat = np.load(self._get_npy_path('loc', self.mode))#, allow_pickle=True)\n",
        "        self.vel_feat = np.load(self._get_npy_path('vel', self.mode))#, allow_pickle=True)\n",
        "        #self.edge_feat = np.load(self._get_npy_path('edges', self.mode))\n",
        "\n",
        "        # Perform preprocessing.\n",
        "        if self.dynamic_len:\n",
        "            self.loc_feat = [normalize(feat, self.loc_max, self.loc_min) for feat in self.loc_feat]\n",
        "            self.vel_feat = [normalize(feat, self.vel_max, self.vel_min) for feat in self.vel_feat]\n",
        "            self.feat = [np.concatenate([loc_feat, vel_feat], axis=-1) for loc_feat, vel_feat in zip(self.loc_feat, self.vel_feat)]\n",
        "            self.feat = [torch.from_numpy(np.array(feat, dtype=np.float32)) for feat in self.feat]\n",
        "            print(\"FEATURE LEN: \",len(self.feat))\n",
        "        else:\n",
        "            self.loc_feat = normalize(\n",
        "                self.loc_feat, self.loc_max, self.loc_min)\n",
        "            self.vel_feat = normalize(\n",
        "                self.vel_feat, self.vel_max, self.vel_min)\n",
        "\n",
        "            # Reshape [num_sims, num_timesteps, num_agents, num_dims]\n",
        "            #self.loc_feat = np.transpose(self.loc_feat, [0, 1, 3, 2])\n",
        "            #self.vel_feat = np.transpose(self.vel_feat, [0, 1, 3, 2])\n",
        "            self.feat = np.concatenate([self.loc_feat, self.vel_feat], axis=-1)\n",
        "\n",
        "            # Convert to pytorch cuda tensor.\n",
        "            self.feat = torch.from_numpy(\n",
        "                np.array(self.feat, dtype=np.float32))  # .cuda()\n",
        "\n",
        "            # Only extract the first 49 frame if testing.\n",
        "            if self.mode == 'test' and not self.test_full:\n",
        "                self.feat = self.feat[:, :49]\n",
        "\n",
        "    def _get_npy_path(self, feat, mode):\n",
        "        return '%s/%s_%s_%s.npy' % (self.data_path,\n",
        "                                    feat,\n",
        "                                    mode,\n",
        "                                    self.name)\n"
      ],
      "metadata": {
        "id": "OAaFr46UvLdN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8yQzALV3GNP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_lBpeKAP3wWb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UbW4QsJt3yiP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH='drive/MyDrive/35'\n",
        "\n",
        "files = glob.glob(f\"{DATA_PATH}/*.npy\")\n",
        "files.sort()\n",
        "files\n",
        "\n",
        "edges = np.load(f'{DATA_PATH}/edges.npy')\n",
        "\n",
        "\n",
        "# Create an adjacency matrix of zeros\n",
        "num_nodes = edges.max() + 1  # Assuming nodes are 0-indexed\n",
        "adj = np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "# Fill in the entries in the adjacency matrix corresponding to edges\n",
        "for i, j in edges:\n",
        "    adj[i, j] = 1\n"
      ],
      "metadata": {
        "id": "FdpDZJSqKNtJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = CmuMotionData('cmu', DATA_PATH, 'train', )\n",
        "val_data = CmuMotionData('cmu', DATA_PATH, 'valid', )\n"
      ],
      "metadata": {
        "id": "8X6mKEW3vhxk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def seed(seed_val):\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    random.seed(seed_val)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "Hdfo_1uisW4j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "\n",
        "class RefNRIMLP(nn.Module):\n",
        "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_hid, n_out, do_prob=0., no_bn=False):\n",
        "        super(RefNRIMLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_in, n_hid),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_out),\n",
        "            nn.ELU(inplace=True)\n",
        "        )\n",
        "        if no_bn:\n",
        "            self.bn = None\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm1d(n_out)\n",
        "\n",
        "    def batch_norm(self, inputs):\n",
        "        orig_shape = inputs.shape\n",
        "        x = inputs.view(-1, inputs.size(-1))\n",
        "        x = self.bn(x)\n",
        "        return x.view(orig_shape)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Input shape: [num_sims, num_things, num_features]\n",
        "        x = self.model(inputs)\n",
        "        if self.bn is not None:\n",
        "            return self.batch_norm(x)\n",
        "        else:\n",
        "            return x\n"
      ],
      "metadata": {
        "id": "sQRXA-ODs2d7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BaseNRI(nn.Module):\n",
        "    def __init__(self, num_vars, encoder, decoder,\n",
        "                 num_edge_types=2,\n",
        "                 no_edge_prior=None,\n",
        "                 gumbel_temp=0.5,\n",
        "                 prior_variance=5e-5):\n",
        "        super(BaseNRI, self).__init__()\n",
        "        self.num_vars = num_vars\n",
        "        self.decoder = decoder\n",
        "        self.encoder = encoder\n",
        "        self.num_edge_types = num_edge_types\n",
        "        self.gumbel_temp = gumbel_temp\n",
        "        self.prior_variance = prior_variance\n",
        "\n",
        "        self.log_prior = self._initialize_log_prior(no_edge_prior)\n",
        "\n",
        "    def _initialize_log_prior(self, no_edge_prior):\n",
        "        prior = torch.zeros(self.num_edge_types)\n",
        "        prior.fill_(1.0 / self.num_edge_types)\n",
        "        log_prior = torch.log(prior).unsqueeze(0).unsqueeze(0)\n",
        "        return log_prior.cuda(non_blocking=True)\n",
        "\n",
        "    def calculate_loss(self, inputs,\n",
        "                       is_train=False,\n",
        "                       teacher_forcing=True,\n",
        "                       return_edges=False,\n",
        "                       return_logits=False):\n",
        "\n",
        "        encoder_results = self.encoder(inputs)\n",
        "        logits = encoder_results['logits']\n",
        "        hard_sample = not is_train\n",
        "        edges = F.gumbel_softmax(logits.view(-1, self.num_edge_types),\n",
        "                                 tau=self.gumbel_temp,\n",
        "                                 hard=hard_sample).view(logits.shape)\n",
        "\n",
        "        output = self.decoder(inputs[:, :-1], edges)\n",
        "\n",
        "        target = inputs[:, 1:] if len(inputs.shape) == 3 else inputs[:, 1:, :, :]\n",
        "\n",
        "        # Negative log likelihood (NLL) for Gaussian distribution\n",
        "        loss_nll = F.mse_loss(output, target) / (2 * self.prior_variance)\n",
        "\n",
        "        # KL divergence with a uniform categorical distribution\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        log_probs = torch.log(probs + 1e-16)\n",
        "        loss_kl = (probs * (log_probs - torch.log(torch.tensor(1.0 / self.num_edge_types)))).sum(-1).mean()\n",
        "\n",
        "        loss = loss_nll + loss_kl\n",
        "\n",
        "        return loss, loss_nll, loss_kl, logits, output\n",
        "\n",
        "    def predict_future(self, inputs, prediction_steps, return_edges=False, return_everything=False):\n",
        "        encoder_dict = self.encoder(inputs)\n",
        "        logits = encoder_dict['logits']\n",
        "        edges = nn.functional.gumbel_softmax(logits.view(-1, self.num_edge_types), tau=self.gumbel_temp, hard=True).view(logits.shape)\n",
        "        tmp_predictions, decoder_state = self.decoder(inputs[:, :-1], edges, return_state=True)\n",
        "        predictions = self.decoder(inputs[:, -1].unsqueeze(1), edges, prediction_steps=prediction_steps, teacher_forcing=False, state=decoder_state)\n",
        "        if return_everything:\n",
        "            predictions = torch.cat([tmp_predictions, predictions], dim=1)\n",
        "        return (predictions, edges) if return_edges else predictions\n"
      ],
      "metadata": {
        "id": "CaQvu7Slstrv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1915a1Ybyarp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseEncoder(nn.Module):\n",
        "    def __init__(self, num_vars):\n",
        "        super(BaseEncoder, self).__init__()\n",
        "        self.num_vars = num_vars\n",
        "        edges = torch.ones(num_vars) - torch.eye(num_vars)\n",
        "        self.send_edges, self.recv_edges = torch.where(edges)\n",
        "\n",
        "        # Encode one-hot representation\n",
        "        one_hot_recv = torch.nn.functional.one_hot(self.recv_edges, num_classes=num_vars)\n",
        "        self.edge2node_mat = nn.Parameter(one_hot_recv.float().T, requires_grad=False)\n",
        "\n",
        "    def node2edge(self, node_embeddings):\n",
        "        send_embed = node_embeddings[:, self.send_edges]\n",
        "        recv_embed = node_embeddings[:, self.recv_edges]\n",
        "        return torch.cat([send_embed, recv_embed], dim=2)\n",
        "\n",
        "    def edge2node(self, edge_embeddings):\n",
        "        incoming = torch.matmul(self.edge2node_mat, edge_embeddings)\n",
        "        # if self.dynamic:\n",
        "        #     old_shape = edge_embeddings.shape\n",
        "        #     incoming = incoming.view(old_shape[0], -1, old_shape[2], old_shape[3])\n",
        "        return incoming / (self.num_vars - 1)\n",
        "\n",
        "\n",
        "class RefMLPEncoder(BaseEncoder):\n",
        "    def __init__(self, num_vars=31, input_size=6, input_time_steps=50, encoder_mlp_hidden=256, encoder_hidden=256, num_edge_types=2, encoder_dropout=0.):\n",
        "        super(RefMLPEncoder, self).__init__(num_vars)\n",
        "        inp_size = input_size * input_time_steps\n",
        "        hidden_size = encoder_hidden\n",
        "        num_layers = 3\n",
        "        self.input_time_steps = input_time_steps\n",
        "\n",
        "        # Define MLP layers\n",
        "        self.mlp1 = RefNRIMLP(inp_size, hidden_size, hidden_size, encoder_dropout)\n",
        "        self.mlp2 = RefNRIMLP(hidden_size * 2, hidden_size, hidden_size, encoder_dropout)\n",
        "        self.mlp3 = RefNRIMLP(hidden_size, hidden_size, hidden_size, encoder_dropout)\n",
        "        mlp4_inp_size = hidden_size * 2\n",
        "        self.mlp4 = RefNRIMLP(mlp4_inp_size, hidden_size, hidden_size, encoder_dropout)\n",
        "\n",
        "        # Define final fully connected layer\n",
        "        if num_layers == 1:\n",
        "            self.fc_out = nn.Linear(hidden_size, num_edge_types)\n",
        "        else:\n",
        "            layers = [nn.Linear(hidden_size, encoder_mlp_hidden), nn.ELU(inplace=True)]\n",
        "            layers += [nn.Linear(encoder_mlp_hidden, encoder_mlp_hidden), nn.ELU(inplace=True)] * (num_layers - 2)\n",
        "            layers.append(nn.Linear(encoder_mlp_hidden, num_edge_types))\n",
        "            self.fc_out = nn.Sequential(*layers)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        print(\"Using MLP encoder.\")\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def forward(self, inputs, return_state=False):\n",
        "\n",
        "        if inputs.size(1) > self.input_time_steps:\n",
        "            inputs = inputs[:, -self.input_time_steps:]\n",
        "        elif inputs.size(1) < self.input_time_steps:\n",
        "            begin_inp = inputs[:, 0:1].expand(-1, self.input_time_steps-inputs.size(1), -1, -1)\n",
        "            inputs = torch.cat([begin_inp, inputs], dim=1)\n",
        "\n",
        "        x = inputs.transpose(1, 2).contiguous().view(inputs.size(0), inputs.size(2), -1)\n",
        "        # New shape: [num_sims, num_atoms, num_timesteps*num_dims]\n",
        "        x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "\n",
        "        x = self.node2edge(x)\n",
        "        x = self.mlp2(x)\n",
        "\n",
        "        x = self.edge2node(x)\n",
        "        x = self.mlp3(x)\n",
        "\n",
        "        x = self.node2edge(x)\n",
        "        x = self.mlp4(x)\n",
        "        result =  self.fc_out(x)\n",
        "        result_dict = {\n",
        "            'logits': result,\n",
        "            'state': inputs,\n",
        "        }\n",
        "        return result_dict\n"
      ],
      "metadata": {
        "id": "bsbsdqlUVSu6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomGRU(nn.Module):\n",
        "    def __init__(self,input_size, n_hid,num_vars=31):\n",
        "        super(CustomGRU, self).__init__()\n",
        "        self.num_vars = num_vars\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "    def forward(self, inputs, agg_msgs, hidden):\n",
        "        inp_r = self.input_r(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_i = self.input_i(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_n = self.input_n(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        hidden = (1 - i)*n + i*hidden\n",
        "\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "-tIG1_vtohpk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphRNNDecoder(nn.Module):\n",
        "    def __init__(self, num_vars=31, input_size=6, decoder_dropout=0., decoder_hidden=64, num_edge_types=2, skip_first=True):\n",
        "        super(GraphRNNDecoder, self).__init__()\n",
        "        self.num_vars = num_vars\n",
        "        self.msg_out_shape = decoder_hidden\n",
        "        self.skip_first_edge_type = skip_first\n",
        "        self.dropout_prob = decoder_dropout\n",
        "        self.edge_types = num_edge_types\n",
        "        # Edge-related definitions\n",
        "        self.msg_fc1 = nn.ModuleList([nn.Linear(2 * decoder_hidden, decoder_hidden) for _ in range(self.edge_types)])\n",
        "        self.msg_fc2 = nn.ModuleList([nn.Linear(decoder_hidden, decoder_hidden) for _ in range(self.edge_types)])\n",
        "\n",
        "        self.custom_gru = CustomGRU(input_size, decoder_hidden)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(decoder_hidden, decoder_hidden)\n",
        "        self.out_fc2 = nn.Linear(decoder_hidden, decoder_hidden)\n",
        "        self.out_fc3 = nn.Linear(decoder_hidden, input_size)\n",
        "\n",
        "        self.msg_out_shape = decoder_hidden\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = decoder_dropout\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = torch.FloatTensor(encode_onehot(self.recv_edges))\n",
        "        self.edge2node_mat = self.edge2node_mat.cuda(non_blocking=True)\n",
        "\n",
        "    def single_step_forward(self, inputs, rel_type, hidden):\n",
        "        # Inputs: [batch, num_atoms, num_dims]\n",
        "        # Hidden: [batch, num_atoms, msg_out]\n",
        "        # rel_type: [batch_size, num_atoms*(num_atoms-1), num_edge_types]\n",
        "\n",
        "        # node2edge\n",
        "        receivers = hidden[:, self.recv_edges, :]\n",
        "        senders = hidden[:, self.send_edges, :]\n",
        "\n",
        "        # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1), self.msg_out_shape, device=inputs.device)\n",
        "\n",
        "        start_idx = 1 if self.skip_first_edge_type else 0\n",
        "        norm = float(len(self.msg_fc2) - start_idx)\n",
        "\n",
        "        # Run separate MLP for every edge type\n",
        "        for i in range(start_idx, len(self.msg_fc2)):\n",
        "            msg = torch.tanh(self.msg_fc1[i](pre_msg))\n",
        "            msg = F.dropout(msg, p=self.dropout_prob)\n",
        "            msg = torch.tanh(self.msg_fc2[i](msg))\n",
        "            msg = msg * rel_type[:, :, i:i+1]\n",
        "            all_msgs += msg / norm\n",
        "\n",
        "        # This step sums all of the messages per node\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1) / (self.num_vars - 1)\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        hidden = self.custom_gru(inputs, agg_msgs, hidden)\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=self.dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = inputs + pred\n",
        "\n",
        "        return pred, hidden\n",
        "\n",
        "    def forward(self, inputs, sampled_edges,\n",
        "                teacher_forcing=False,\n",
        "                return_state=False,\n",
        "                prediction_steps=-1,\n",
        "                state=None):\n",
        "\n",
        "        batch_size, time_steps, num_vars, num_feats = inputs.size()\n",
        "        pred_steps = prediction_steps if prediction_steps > 0 else time_steps\n",
        "\n",
        "        if len(sampled_edges.shape) == 3:\n",
        "            sampled_edges = sampled_edges.unsqueeze(1).expand(batch_size, pred_steps, -1, -1)\n",
        "\n",
        "        if state is None:\n",
        "            hidden = torch.zeros(batch_size,\n",
        "                               num_vars,\n",
        "                               self.msg_out_shape,\n",
        "                               device=inputs.device)\n",
        "        else:\n",
        "            hidden = state\n",
        "        teacher_forcing_steps = time_steps\n",
        "\n",
        "        pred_all = []\n",
        "        for step in range(pred_steps):\n",
        "            if step == 0 or (teacher_forcing and step < teacher_forcing_steps):\n",
        "                ins = inputs[:, step, :]\n",
        "            else:\n",
        "                ins = pred_all[-1]\n",
        "\n",
        "            pred, hidden = self.single_step_forward(ins, sampled_edges[:, step, :], hidden)\n",
        "            pred_all.append(pred)\n",
        "\n",
        "        preds = torch.stack(pred_all, dim=1)\n",
        "\n",
        "        return (preds, hidden) if return_state else preds\n"
      ],
      "metadata": {
        "id": "XeMqduheyWPk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uD9lvJD_Ribe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_vars = 31\n",
        "input_size = 6\n",
        "hidden_size = 64\n",
        "num_edge_types = 2\n",
        "# Build Encoder\n",
        "encoder = RefMLPEncoder()\n",
        "print(\"ENCODER: \",encoder)\n",
        "\n",
        "# # Build Decoder\n",
        "decoder = GraphRNNDecoder()#num_vars, input_size, hidden_size, num_edge_types)\n",
        "print(\"DECODER: \",decoder)\n",
        "\n",
        "model = BaseNRI(num_vars, encoder, decoder)\n",
        "model = model.cuda()\n"
      ],
      "metadata": {
        "id": "fo5Bclp8yGU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d370483e-0d55-430b-fe80-047a3c9ba139"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using MLP encoder.\n",
            "ENCODER:  RefMLPEncoder(\n",
            "  (mlp1): RefNRIMLP(\n",
            "    (model): Sequential(\n",
            "      (0): Linear(in_features=300, out_features=256, bias=True)\n",
            "      (1): ELU(alpha=1.0, inplace=True)\n",
            "      (2): Dropout(p=0.0, inplace=False)\n",
            "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (4): ELU(alpha=1.0, inplace=True)\n",
            "    )\n",
            "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (mlp2): RefNRIMLP(\n",
            "    (model): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (1): ELU(alpha=1.0, inplace=True)\n",
            "      (2): Dropout(p=0.0, inplace=False)\n",
            "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (4): ELU(alpha=1.0, inplace=True)\n",
            "    )\n",
            "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (mlp3): RefNRIMLP(\n",
            "    (model): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (1): ELU(alpha=1.0, inplace=True)\n",
            "      (2): Dropout(p=0.0, inplace=False)\n",
            "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (4): ELU(alpha=1.0, inplace=True)\n",
            "    )\n",
            "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (mlp4): RefNRIMLP(\n",
            "    (model): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (1): ELU(alpha=1.0, inplace=True)\n",
            "      (2): Dropout(p=0.0, inplace=False)\n",
            "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (4): ELU(alpha=1.0, inplace=True)\n",
            "    )\n",
            "    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (fc_out): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ELU(alpha=1.0, inplace=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ELU(alpha=1.0, inplace=True)\n",
            "    (4): Linear(in_features=256, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Using learned recurrent interaction net decoder.\n",
            "DECODER:  GraphRNNDecoder(\n",
            "  (msg_fc1): ModuleList(\n",
            "    (0-1): 2 x Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (msg_fc2): ModuleList(\n",
            "    (0-1): 2 x Linear(in_features=64, out_features=64, bias=True)\n",
            "  )\n",
            "  (custom_gru): CustomGRU(\n",
            "    (hidden_r): Linear(in_features=64, out_features=64, bias=False)\n",
            "    (hidden_i): Linear(in_features=64, out_features=64, bias=False)\n",
            "    (hidden_h): Linear(in_features=64, out_features=64, bias=False)\n",
            "    (input_r): Linear(in_features=6, out_features=64, bias=True)\n",
            "    (input_i): Linear(in_features=6, out_features=64, bias=True)\n",
            "    (input_n): Linear(in_features=6, out_features=64, bias=True)\n",
            "  )\n",
            "  (out_fc1): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (out_fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (out_fc3): Linear(in_features=64, out_features=6, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = True\n",
        "batch_size = 8\n",
        "val_batch_size = batch_size\n",
        "accumulate_steps = 1\n",
        "training_scheduler = None\n",
        "num_epochs = 100\n",
        "val_interval = 5\n",
        "val_start = 0\n",
        "normalize_nll = True#False\n",
        "normalize_kl = True#False\n",
        "tune_on_nll = True\n",
        "verbose = False\n",
        "continue_training = False\n",
        "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_data_loader = DataLoader(val_data, batch_size=val_batch_size)\n",
        "lr = 5e-4\n",
        "wd = 0.\n",
        "mom = 0.\n"
      ],
      "metadata": {
        "id": "yikavfym33za"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FL210IZJuCTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = [param for param in model.parameters() if param.requires_grad]\n",
        "opt = torch.optim.Adam(model_params, lr=lr, weight_decay=wd)\n"
      ],
      "metadata": {
        "id": "2Mhed1e_xvcE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = 1\n",
        "best_val_epoch = -1\n",
        "best_val_result = 10000000\n"
      ],
      "metadata": {
        "id": "15c5G5SyyEy4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_decay_steps=500\n",
        "lr_decay_factor=0.5\n",
        "training_scheduler = torch.optim.lr_scheduler.StepLR(opt,\n",
        "                                                     lr_decay_steps,\n",
        "                                                     lr_decay_factor)\n",
        "end = start = 0\n",
        "seed(1)\n"
      ],
      "metadata": {
        "id": "bFVsKPaYkyvu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Define the tqdm object\n",
        "pbar = tqdm(range(start_epoch, num_epochs + 1), desc='Epochs')\n",
        "\n",
        "for epoch in pbar:\n",
        "    model.train()\n",
        "    model.train_percent = epoch / num_epochs\n",
        "    total_training_loss = 0\n",
        "    for batch in train_data_loader:\n",
        "        inputs = batch['inputs'].cuda(non_blocking=True) if gpu else batch['inputs']\n",
        "        loss, _, _, _, _ = model.calculate_loss(inputs, is_train=True, return_logits=True)\n",
        "        loss.backward()\n",
        "        opt.step() # Updating the weights\n",
        "        opt.zero_grad() # Zeroing the gradients for the next batch\n",
        "        total_training_loss += loss.item()\n",
        "\n",
        "    if training_scheduler is not None:\n",
        "        training_scheduler.step()\n",
        "\n",
        "    total_nll, total_kl = 0, 0\n",
        "    for batch in val_data_loader:\n",
        "        inputs = batch['inputs'].cuda(non_blocking=True) if gpu else batch['inputs']\n",
        "        _, loss_nll, loss_kl, _, _ = model.calculate_loss(inputs, is_train=False, teacher_forcing=True, return_logits=True)\n",
        "        total_kl += loss_kl.sum().item()\n",
        "        total_nll += loss_nll.sum().item()\n",
        "\n",
        "    total_kl /= len(val_data)\n",
        "    total_nll /= len(val_data)\n",
        "    total_loss = total_kl + total_nll\n",
        "    tuning_loss = total_nll if tune_on_nll else total_loss\n",
        "\n",
        "    if tuning_loss < best_val_result:\n",
        "        best_val_epoch, best_val_result = epoch, tuning_loss\n",
        "\n",
        "    pbar.set_postfix({'Best Training Loss': total_training_loss, 'Best Validation Loss': best_val_result})\n"
      ],
      "metadata": {
        "id": "D1KBnXuclJ1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddce5e0f-af29-480e-eabb-633dcf71c2e3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 100%|██████████| 100/100 [04:44<00:00,  2.84s/it, Best Training Loss=90.1, Best Validation Loss=1.08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def eval_forward_prediction(model, dataset, burn_in_steps, forward_pred_steps, gpu=True, batch_size=8, return_total_errors=False):\n",
        "    dataset.return_edges = False\n",
        "\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, pin_memory=gpu)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        with torch.no_grad():\n",
        "            model_inputs = inputs[:, :burn_in_steps]\n",
        "            gt_predictions = inputs[:, burn_in_steps:burn_in_steps+forward_pred_steps]\n",
        "            if gpu:\n",
        "                model_inputs = model_inputs.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future(model_inputs, forward_pred_steps).cpu()\n",
        "            batch_count += 1\n",
        "            if return_total_errors:\n",
        "                all_errors.append(F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1))\n",
        "            else:\n",
        "                total_se += F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1).sum(dim=0)\n",
        "    if return_total_errors:\n",
        "        return torch.cat(all_errors, dim=0)\n",
        "    else:\n",
        "        return total_se / len(dataset)"
      ],
      "metadata": {
        "id": "TxhmYD7vszrm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = CmuMotionData('cmu', DATA_PATH, 'test', test_full=True)\n",
        "mode='eval'\n",
        "if mode == 'eval':\n",
        "    test_cumulative_mse = eval_forward_prediction(model, test_data, 50, 48)\n",
        "    # path = os.path.join(args.working_dir, args.error_out_name)\n",
        "    # np.save(path, test_cumulative_mse.cpu().numpy())\n",
        "    test_mse_1 = test_cumulative_mse[0].item()\n",
        "    test_mse_20 = test_cumulative_mse[19].item()\n",
        "    test_mse_40 = test_cumulative_mse[39].item()\n",
        "    print(\"FORWARD PRED RESULTS:\")\n",
        "    print(\"\\t1 STEP:  \",test_mse_1)\n",
        "    print(\"\\t20 STEP: \", test_mse_20)\n",
        "    print(\"\\t40 STEP: \",test_mse_40)\n"
      ],
      "metadata": {
        "id": "BhJmzHpvlxAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729ca4d8-ef12-499f-cff3-38dfaf7f4624"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FORWARD PRED RESULTS:\n",
            "\t1 STEP:   8.486501610605046e-05\n",
            "\t20 STEP:  0.0006076358258724213\n",
            "\t40 STEP:  0.0011646547354757786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.semilogy(test_cumulative_mse)\n",
        "plt.xlabel('Timesteps')\n",
        "plt.ylabel('MSE')"
      ],
      "metadata": {
        "id": "Fc99MYVssgkM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "e85648ef-f2fb-4d23-ef62-9eb923ad41d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'MSE')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fKpE3IFDtHvs"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}