{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse vs Dense Graph Representations\n"
      ],
      "metadata": {
        "id": "fayE-uJ37uMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code snippet demonstrates the implementation of the GraphSAGE model with both dense and sparse data representations for node classification on the 'ogbn-products' dataset from the OGB (Open Graph Benchmark). (Spoiler: the dense representation will overwhelm the GPU, unless you have at least 50GB of usable GPU memory. The sparse representation takes up about half the GPU RAM.)\n",
        "\n",
        "Two distinct GraphSAGE classes are defined for handling sparse and dense data. The code leverages pynvml to monitor GPU memory usage during model training and testing.\n",
        "\n",
        "The user has the flexibility to choose between the sparse or dense representation by toggling the use_sparse variable. Correspondingly, different versions of the train and test functions are defined and selected to handle the selected data representation. The functions record and print out the loss, correctness, and GPU memory usage during execution.\n",
        "\n",
        "The model, once trained, is tested, and the predictions, true labels, and memory usage are printed out. Finally, the pynvml library is shut down to free up resources."
      ],
      "metadata": {
        "id": "Youg3nWRYwwo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YCLfvZy0umD"
      },
      "source": [
        "## Overview of Graph Representations in Pytorch Geometric\n",
        "###Sparse Graphs\n",
        "In the context of graph neural networks, sparse graphs are typically represented using adjacency matrices. An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph. For large graphs, the adjacency matrix can be highly sparse, meaning that most of the elements are zero. In practice, we only store the non-zero elements to save memory and computational resources. This is particularly crucial for large-scale graphs like social networks, citation networks, etc., where the number of nodes can be in the millions or more.\n",
        "\n",
        "###Dense Graphs\n",
        "On the other hand, dense graphs or graph data represented in a dense format often use an edge list for representation. An edge list consists of pairs of nodes that have a direct edge between them. It’s a simple and explicit way to represent a graph but can be inefficient for large, sparse graphs, as it doesn't exploit the sparsity of the data.\n",
        "\n",
        "###Differences in GraphSAGE Classes\n",
        "#####Input Data Format:\n",
        "\n",
        "GraphSAGE_sparse: Takes adjacency matrices as input. The forward method accepts adj_t (a sparse tensor representation of the adjacency matrix).\n",
        "\n",
        "GraphSAGE_dense: Takes edge lists as input. The forward method accepts edge_index that provides the indices of the source and target nodes for each edge.\n",
        "#####Memory Efficiency:\n",
        "\n",
        "GraphSAGE_sparse: More memory-efficient for large, sparse graphs as it only stores non-zero elements of the adjacency matrix.\n",
        "\n",
        "GraphSAGE_dense: Can be less efficient in terms of memory for large, sparse graphs but is suitable for smaller or denser graphs.\n",
        "#####Computational Efficiency:\n",
        "\n",
        "GraphSAGE_sparse: Can be computationally efficient for certain operations due to the sparse nature of the data.\n",
        "\n",
        "GraphSAGE_dense: May involve more computations as it deals with the entire edge list or adjacency matrix.\n",
        "Code Adaptability:\n",
        "\n",
        "The two classes ensure that the GraphSAGE model can be easily adapted to different data formats and storage requirements, offering flexibility to the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bVkSWvu0D1K"
      },
      "outputs": [],
      "source": [
        "#Uninstall the current CUDA version\n",
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg3h5HXP0Dok",
        "outputId": "f5918a81-eb0c-48a6-a923-1bd8e9d8baec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-18 22:28:42--  https://developer.download.nvidia.com/compute/cuda/11.6.0/local_installers/cuda-repo-ubuntu1804-11-6-local_11.6.0-510.39.01-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.20.126\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.20.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2681108236 (2.5G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1804-11-6-local_11.6.0-510.39.01-1_amd64.deb’\n",
            "\n",
            "cuda-repo-ubuntu180 100%[===================>]   2.50G   281MB/s    in 9.5s    \n",
            "\n",
            "2023-10-18 22:28:51 (270 MB/s) - ‘cuda-repo-ubuntu1804-11-6-local_11.6.0-510.39.01-1_amd64.deb’ saved [2681108236/2681108236]\n",
            "\n",
            "--2023-10-18 22:28:51--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
            "Reusing existing connection to developer.download.nvidia.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2942 (2.9K) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1804_10.0.130-1_amd64.deb’\n",
            "\n",
            "cuda-repo-ubuntu180 100%[===================>]   2.87K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-18 22:28:51 (288 MB/s) - ‘cuda-repo-ubuntu1804_10.0.130-1_amd64.deb’ saved [2942/2942]\n",
            "\n",
            "FINISHED --2023-10-18 22:28:51--\n",
            "Total wall clock time: 9.6s\n",
            "Downloaded: 2 files, 2.5G in 9.5s (270 MB/s)\n",
            "Selecting previously unselected package cuda-repo-ubuntu1804-11-6-local.\n",
            "(Reading database ... 119205 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1804-11-6-local_11.6.0-510.39.01-1_amd64.deb ...\n",
            "Unpacking cuda-repo-ubuntu1804-11-6-local (11.6.0-510.39.01-1) ...\n",
            "Setting up cuda-repo-ubuntu1804-11-6-local (11.6.0-510.39.01-1) ...\n",
            "\n",
            "The public CUDA GPG key does not appear to be installed.\n",
            "To install the key, run this command:\n",
            "sudo apt-key add /var/cuda-repo-ubuntu1804-11-6-local/7fa2af80.pub\n",
            "\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Executing: /tmp/apt-key-gpghome.crvrZhzonr/gpg.1.sh --fetch-keys https://developer.download.nvidia.com/compute/cuda-repo-ubuntu1804-11-6-local/7fa2af80.pub\n",
            "gpg: requesting key from 'https://developer.download.nvidia.com/compute/cuda-repo-ubuntu1804-11-6-local/7fa2af80.pub'\n",
            "gpg: WARNING: unable to fetch URI https://developer.download.nvidia.com/compute/cuda-repo-ubuntu1804-11-6-local/7fa2af80.pub: No data\n",
            "Get:1 file:/var/cuda-repo-ubuntu1804-11-6-local  InRelease\n",
            "Ign:1 file:/var/cuda-repo-ubuntu1804-11-6-local  InRelease\n",
            "Get:2 file:/var/cuda-repo-ubuntu1804-11-6-local  Release [564 B]\n",
            "Get:2 file:/var/cuda-repo-ubuntu1804-11-6-local  Release [564 B]\n",
            "Get:3 file:/var/cuda-repo-ubuntu1804-11-6-local  Release.gpg [836 B]\n",
            "Get:3 file:/var/cuda-repo-ubuntu1804-11-6-local  Release.gpg [836 B]\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Ign:3 file:/var/cuda-repo-ubuntu1804-11-6-local  Release.gpg\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Reading package lists... Done\n",
            "W: GPG error: file:/var/cuda-repo-ubuntu1804-11-6-local  Release: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY F60F4B3D7FA2AF80\n",
            "E: The repository 'file:/var/cuda-repo-ubuntu1804-11-6-local  Release' is not signed.\n",
            "N: Updating from such a repository can't be done securely, and is therefore disabled by default.\n",
            "N: See apt-secure(8) manpage for repository creation and user configuration details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package cuda-11-6\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Download CUDA 11.6\n",
        "!wget  --no-clobber https://developer.download.nvidia.com/compute/cuda/11.6.0/local_installers/cuda-repo-ubuntu1804-11-6-local_11.6.0-510.39.01-1_amd64.deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "#install CUDA kit dpkg\n",
        "!dpkg -i cuda-repo-ubuntu1804-11-6-local_11.6.0-510.39.01-1_amd64.deb\n",
        "!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda-repo-ubuntu1804-11-6-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-11-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTQ_IGcu0DjX",
        "outputId": "8015fd14-6412-447e-b44d-f7c9c223c771"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.0.1+cu118\n",
            "Uninstalling torch-2.0.1+cu118:\n",
            "  Successfully uninstalled torch-2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nAkZrFM0DgX",
        "outputId": "9a1cb434-82f3-4b75-aa2d-a741291909cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch==1.13.0\n",
            "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0) (4.5.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (0.41.2)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.0 -f https://data.pyg.org/whl/torch-1.13.0+cu116.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMw5g9Uc0DcO"
      },
      "outputs": [],
      "source": [
        "!pip install psutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqRRLRMz0DUt",
        "outputId": "7b259bef-fd95-48f7-b664-7d641f5dc873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.7\n"
          ]
        }
      ],
      "source": [
        "# Find the CUDA version PyTorch was installed with\n",
        "!python -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7yyBuh60R0A",
        "outputId": "d1f5b6b6-487c-4745-a52e-95bb93424523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu117\n"
          ]
        }
      ],
      "source": [
        "# PyTorch version\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-lMqid90UW5",
        "outputId": "c532474e-46f9-4db5-bb56-3233970f5ee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu117.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu117/pyg_lib-0.3.0%2Bpt113cu117-cp310-cp310-linux_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Building wheels for collected packages: torch-scatter, torch-sparse\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for torch-scatter\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for torch-scatter\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for torch-sparse\n",
            "Failed to build torch-scatter torch-sparse\n",
            "\u001b[31mERROR: Could not build wheels for torch-scatter, torch-sparse, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEntUWm42l8P"
      },
      "source": [
        "313pm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QwUsfhe50X4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8adc459d-cfc3-4c07-acca-00fde3c370bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ogb in /usr/local/lib/python3.10/dist-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.13.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.6)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->ogb) (0.41.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2023.7.22)\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ogb\n",
        "!pip install pynvml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hBBbxO2Jz1pl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.transforms import ToSparseTensor\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "import numpy as np\n",
        "import pynvml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use pynvml to get the GPU memory usage. This function can be placed anywhere in the code. In the example below, it is placed after the epoch. When I trouble shoot memory issues, one simple way to profile the code is to place this function in serveral spots in the code, as one would with debugging print statements.\n"
      ],
      "metadata": {
        "id": "ZKDKcZGnYeX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize NVML\n",
        "pynvml.nvmlInit()\n",
        "\n",
        "# Function to get the current GPU memory usage using pynvml\n",
        "def get_gpu_memory_usage():\n",
        "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # 0 is GPU index\n",
        "    info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "    return info.used / 1024 / 1024  # convert to MB"
      ],
      "metadata": {
        "id": "y_iMlkOtVb9x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ6MChsDz1pl"
      },
      "source": [
        "Definition of the GraphSAGE model for sparse data. These layers use adjacency matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xu7tyicCz1pm"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE_sparse(torch.nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
        "        self.conv3 = SAGEConv(hidden_dim, out_dim)\n",
        "    def forward(self, x, adj_t):\n",
        "        x = self.conv1(x, adj_t)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout)\n",
        "        x = self.conv2(x, adj_t)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout)\n",
        "        x = self.conv3(x, adj_t)\n",
        "        return torch.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QOYSs8oz1pm"
      },
      "source": [
        "Definition of the GraphSAGE model for dense data. These layers use edge indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dmWXGyWhz1pm"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE_dense(torch.nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
        "        self.conv3 = SAGEConv(hidden_dim, out_dim)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return torch.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqZN8xM6z1pm"
      },
      "source": [
        "Train and test functions for the sparse representation. In this simple example, there is only one epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OQQEvJgmz1pn"
      },
      "outputs": [],
      "source": [
        "def train_sparse(model, data, optimizer):\n",
        "    model.train()\n",
        "    data = data.to('cuda')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.adj_t)  # Use adj_t for sparse tensor representation\n",
        "    loss = F.cross_entropy(out, data.y.squeeze(1).long())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    memory_usage = get_gpu_memory_usage()  # Getting memory usage with pynvml\n",
        "\n",
        "    correct = (out.argmax(dim=1) == data.y.squeeze(1)).sum().item()\n",
        "    return loss.item(), correct, memory_usage\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_sparse(model, data):\n",
        "    model.eval()\n",
        "    data = data.to('cuda')\n",
        "\n",
        "    out = model(data.x, data.adj_t)  # Use adj_t for sparse tensor representation\n",
        "    pred = out.argmax(dim=1)\n",
        "\n",
        "    memory_usage = get_gpu_memory_usage()  # Getting memory usage with pynvml\n",
        "\n",
        "    return pred.cpu(), data.y.cpu(), memory_usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXIAMulSz1pn"
      },
      "source": [
        "Training/Test functions for dense. Again, we opt for one epoch in this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tACbl-9gz1pn"
      },
      "outputs": [],
      "source": [
        "def train_dense(model, data, optimizer):\n",
        "    model.train()\n",
        "    data = data.to('cuda')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out, data.y.squeeze(1).long())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    memory_usage = get_gpu_memory_usage()  # Getting memory usage with pynvml\n",
        "\n",
        "    correct = (out.argmax(dim=1) == data.y.squeeze(1)).sum().item()\n",
        "    return loss.item(), correct, memory_usage\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_dense(model, data):\n",
        "    model.eval()\n",
        "    data = data.to('cuda')\n",
        "\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1)\n",
        "\n",
        "    memory_usage = get_gpu_memory_usage()  # Getting memory usage with pynvml\n",
        "\n",
        "    return pred.cpu(), data.y.cpu(), memory_usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UshDoxAz1pn"
      },
      "source": [
        "Choose whether to use sparse or dense data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OG9y_5Yaz1pn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2384981b-d79c-457c-eaa4-24569d75893a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/sparse.py:264: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
            "  adj = torch.sparse_csr_tensor(\n"
          ]
        }
      ],
      "source": [
        "# Choose either sparse or dense\n",
        "use_sparse = True  # Set to True for sparse, False for dense\n",
        "\n",
        "if use_sparse:\n",
        "    # Load the dataset\n",
        "    dataset = PygNodePropPredDataset(name='ogbn-products', transform=T.ToSparseTensor())\n",
        "    data = dataset[0]\n",
        "    model = GraphSAGE_sparse(dataset.num_features, 128, dataset.num_classes)\n",
        "    train = train_sparse\n",
        "    test = test_sparse\n",
        "else:\n",
        "    # Load the dataset\n",
        "    dataset = PygNodePropPredDataset(name='ogbn-products')\n",
        "    data = dataset[0]\n",
        "    model = GraphSAGE_dense(dataset.num_features, 128, dataset.num_classes)\n",
        "    train = train_dense\n",
        "    test = test_dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our scenario, opting for a sparse representation should work fine. Opting for a dense representation of the data will lead to an `OutOfMemoryError`.\n",
        "\n",
        "This error occurs when the GPU runs out of memory during the training process, which is attributed to the large memory requirement of handling dense data representations. The attempted allocation of 46.09 GiB of memory surpasses the total GPU capacity, causing the error.\n",
        "\n",
        "One effective strategy to mitigate such memory issues is implementing mini-batching. Mini-batching breaks down the dataset into smaller, manageable batches, reducing the amount of memory needed at any given time. In the context of the Section 8.7 notebook, mini-batching is successfully applied to handle the same dense representation without overwhelming the memory, thus preventing the `OutOfMemoryError`."
      ],
      "metadata": {
        "id": "ojyq8ZNLXFlj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "59vw8XyNz1pn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467183a6-debc-478f-a810-9ed879be1fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.849055767059326, Correct: 47747, Memory Used: 24667.4375 MB\n",
            "Predictions: tensor([10,  4,  4,  ...,  8,  4,  4]), True Labels: tensor([[0],\n",
            "        [1],\n",
            "        [2],\n",
            "        ...,\n",
            "        [8],\n",
            "        [2],\n",
            "        [4]]), Memory Used: 24667.4375 MB\n"
          ]
        }
      ],
      "source": [
        "model = model.to('cuda')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training and testing the model\n",
        "loss, correct, train_memory = train(model, data, optimizer)\n",
        "print(f\"Loss: {loss}, Correct: {correct}, Memory Used: {train_memory} MB\")\n",
        "\n",
        "pred, true_labels, test_memory = test(model, data)\n",
        "print(f\"Predictions: {pred}, True Labels: {true_labels}, Memory Used: {test_memory} MB\")\n",
        "\n",
        "# Shutdown NVML\n",
        "pynvml.nvmlShutdown()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_eRL7lqGUbrf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}